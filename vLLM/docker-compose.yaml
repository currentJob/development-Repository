version: "3.8"

services:
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm-deepseek
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ./models/DeepSeek-R1-Distill-Qwen-1.5B:/model
      # - ./models/deepseek-llm-7b-chat:/model
    command: >
      --model /model
      --tokenizer /model
      --trust-remote-code
      --dtype float16
      --gpu-memory-utilization 0.9
      --max-model-len 8192
      --port 8000