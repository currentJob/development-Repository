{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n",
      "Fri Apr  4 11:18:31 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.16                 Driver Version: 572.16         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   62C    P8              6W /   80W |     432MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1688    C+G   ...munity\\Common7\\IDE\\devenv.exe      N/A      |\n",
      "|    0   N/A  N/A           11184    C+G   ...iceHub.ThreadedWaitDialog.exe      N/A      |\n",
      "|    0   N/A  N/A           11492    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           22504    C+G   ...et8.0-windows\\RTMS.UI.WPF.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.6103\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.4055\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.2876\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2166\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1749\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.1519\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.1371\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.1282\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1218\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1175\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1144\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1117\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 7s 2s/step - loss: 0.1096\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.1083\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.1072\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.1065\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.1057\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.1052\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.1045\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1038\n",
      "INFO:tensorflow:Assets written to: saved_model_srcnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_srcnn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Tensorflow needs to be built with TensorRT support enabled to allow TF-TRT to operate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Tensorflow needs to be built with TensorRT support enabled to allow TF-TRT to operate.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensorflow has not been built with TensorRT support.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 161\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorrt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trt_convert \u001b[38;5;28;01mas\u001b[39;00m trt\n\u001b[0;32m    156\u001b[0m conversion_params \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mTrtConversionParams(\n\u001b[0;32m    157\u001b[0m     precision_mode\u001b[38;5;241m=\u001b[39mtrt\u001b[38;5;241m.\u001b[39mTrtPrecisionMode\u001b[38;5;241m.\u001b[39mFP16,  \u001b[38;5;66;03m# FP16 or FP32\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     max_workspace_size_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[0;32m    159\u001b[0m )\n\u001b[1;32m--> 161\u001b[0m converter \u001b[38;5;241m=\u001b[39m \u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrtGraphConverterV2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_saved_model_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_model_srcnn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconversion_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconversion_params\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m converter\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[0;32m    167\u001b[0m converter\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrt_saved_model_srcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\f1soft\\anaconda3\\envs\\python-39\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:576\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    569\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    570\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    571\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[0;32m    575\u001b[0m           instructions)\n\u001b[1;32m--> 576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\f1soft\\anaconda3\\envs\\python-39\\lib\\site-packages\\tensorflow\\python\\compiler\\tensorrt\\trt_convert.py:1259\u001b[0m, in \u001b[0;36mTrtGraphConverterV2.__init__\u001b[1;34m(self, input_saved_model_dir, input_saved_model_tags, input_saved_model_signature_key, use_dynamic_shape, dynamic_shape_profile_strategy, max_workspace_size_bytes, precision_mode, minimum_segment_size, maximum_cached_engines, use_calibration, allow_build_at_runtime, conversion_params)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1251\u001b[0m   conversion_params \u001b[38;5;241m=\u001b[39m TrtConversionParams(\n\u001b[0;32m   1252\u001b[0m       max_workspace_size_bytes\u001b[38;5;241m=\u001b[39mmax_workspace_size_bytes,\n\u001b[0;32m   1253\u001b[0m       precision_mode\u001b[38;5;241m=\u001b[39mprecision_mode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1256\u001b[0m       use_calibration\u001b[38;5;241m=\u001b[39muse_calibration,\n\u001b[0;32m   1257\u001b[0m       allow_build_at_runtime\u001b[38;5;241m=\u001b[39mallow_build_at_runtime)\n\u001b[1;32m-> 1259\u001b[0m \u001b[43m_check_trt_version_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1260\u001b[0m _check_conversion_params(conversion_params, is_v2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conversion_params \u001b[38;5;241m=\u001b[39m conversion_params\n",
      "File \u001b[1;32mc:\\Users\\f1soft\\anaconda3\\envs\\python-39\\lib\\site-packages\\tensorflow\\python\\compiler\\tensorrt\\trt_convert.py:223\u001b[0m, in \u001b[0;36m_check_trt_version_compatibility\u001b[1;34m()\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _pywrap_py_utils\u001b[38;5;241m.\u001b[39mis_tensorrt_enabled():\n\u001b[0;32m    219\u001b[0m   logging\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    220\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow needs to be built with TensorRT support enabled to allow \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF-TRT to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 223\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow has not been built with TensorRT support.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    226\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    227\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows support is provided experimentally. No guarantee is made \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregarding functionality or engineering support. Use at your own risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensorflow has not been built with TensorRT support."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Input, ReLU, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 정의\n",
    "def build_advanced_srcnn():\n",
    "    inputs = Input(shape=(FIXED_SIZE[0], FIXED_SIZE[1], 3))\n",
    "    x = Conv2D(128, (9, 9), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(64, (5, 5), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(64, (5, 5), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(3, (3, 3), padding='same')(x)\n",
    "    outputs = Add()([inputs, x])  # Residual 연결\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# 이미지 전처리 함수 (고정 크기로 리사이즈)\n",
    "def preprocess_pair_fixed(image_path, upscale_factor=2):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"이미지를 불러올 수 없습니다: {image_path}\")\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, FIXED_SIZE)  # 고정된 크기로 리사이즈\n",
    "\n",
    "    # 다운샘플 후 업샘플해서 LR 이미지 생성\n",
    "    lr = cv2.resize(img, (FIXED_SIZE[0] // upscale_factor, FIXED_SIZE[1] // upscale_factor), interpolation=cv2.INTER_CUBIC)\n",
    "    lr = cv2.resize(lr, FIXED_SIZE, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # 정규화\n",
    "    lr = lr.astype(np.float32) / 255.0\n",
    "    hr = img.astype(np.float32) / 255.0\n",
    "\n",
    "    return lr, hr\n",
    "\n",
    "# Dataset 생성\n",
    "def create_fixed_dataset(image_dir, batch_size=4):\n",
    "    image_paths = glob(os.path.join(image_dir, \"*.jpg\"))\n",
    "    \n",
    "    def generator():\n",
    "        for path in image_paths:\n",
    "            try:\n",
    "                lr, hr = preprocess_pair_fixed(path, 10)\n",
    "                yield lr, hr\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(FIXED_SIZE[0], FIXED_SIZE[1], 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(FIXED_SIZE[0], FIXED_SIZE[1], 3), dtype=tf.float32),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# 테스트 이미지 전처리 함수\n",
    "def preprocess_test_image(image_path, upscale_factor=2):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise ValueError(\"이미지를 불러올 수 없습니다.\")\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, FIXED_SIZE)\n",
    "\n",
    "    # 다운샘플 후 업샘플 → 입력으로 사용\n",
    "    lr = cv2.resize(img, (FIXED_SIZE[0] // upscale_factor, FIXED_SIZE[1] // upscale_factor), interpolation=cv2.INTER_CUBIC)\n",
    "    lr_up = cv2.resize(lr, FIXED_SIZE, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # 정규화\n",
    "    lr_up_norm = lr_up.astype(np.float32) / 255.0\n",
    "    lr_up_norm = np.expand_dims(lr_up_norm, axis=0)  # 배치 차원 추가\n",
    "\n",
    "    return lr_up_norm, lr, img\n",
    "\n",
    "# 업스케일링 수행\n",
    "def upscale_and_show_trt(image_path):\n",
    "    input_tensor, lr_img, hr_gt = preprocess_test_image(image_path)\n",
    "    input_tensor = tf.constant(input_tensor)\n",
    "\n",
    "    # 추론 실행\n",
    "    output = infer(input_tensor)\n",
    "    \n",
    "    # 키 이름이 레이어 이름과 같음 (확인 필요, 예: 'add')\n",
    "    sr = list(output.values())[0].numpy()[0]\n",
    "    sr = np.clip(sr * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(lr_img)\n",
    "    plt.title(\"Low-Res Input\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(sr)\n",
    "    plt.title(\"TRT-Optimized Output\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(hr_gt)\n",
    "    plt.title(\"Original High-Res\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 고정 입력 이미지 크기 설정\n",
    "FIXED_SIZE = (128, 128)\n",
    "\n",
    "# 데이터 경로\n",
    "image_dir = 'img'\n",
    "dataset = create_fixed_dataset(image_dir)\n",
    "\n",
    "# 모델 컴파일 & 학습\n",
    "model = build_advanced_srcnn()\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='mean_absolute_error')\n",
    "model.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_srcnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_srcnn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Tensorflow needs to be built with TensorRT support enabled to allow TF-TRT to operate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Tensorflow needs to be built with TensorRT support enabled to allow TF-TRT to operate.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensorflow has not been built with TensorRT support.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorrt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trt_convert \u001b[38;5;28;01mas\u001b[39;00m trt\n\u001b[0;32m      6\u001b[0m conversion_params \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mTrtConversionParams(\n\u001b[0;32m      7\u001b[0m     precision_mode\u001b[38;5;241m=\u001b[39mtrt\u001b[38;5;241m.\u001b[39mTrtPrecisionMode\u001b[38;5;241m.\u001b[39mFP16,  \u001b[38;5;66;03m# FP16 or FP32\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     max_workspace_size_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m converter \u001b[38;5;241m=\u001b[39m \u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrtGraphConverterV2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_saved_model_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_model_srcnn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconversion_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconversion_params\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m converter\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[0;32m     17\u001b[0m converter\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrt_saved_model_srcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\f1soft\\anaconda3\\envs\\python-39\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:576\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    569\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    570\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    571\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[0;32m    575\u001b[0m           instructions)\n\u001b[1;32m--> 576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\f1soft\\anaconda3\\envs\\python-39\\lib\\site-packages\\tensorflow\\python\\compiler\\tensorrt\\trt_convert.py:1259\u001b[0m, in \u001b[0;36mTrtGraphConverterV2.__init__\u001b[1;34m(self, input_saved_model_dir, input_saved_model_tags, input_saved_model_signature_key, use_dynamic_shape, dynamic_shape_profile_strategy, max_workspace_size_bytes, precision_mode, minimum_segment_size, maximum_cached_engines, use_calibration, allow_build_at_runtime, conversion_params)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1251\u001b[0m   conversion_params \u001b[38;5;241m=\u001b[39m TrtConversionParams(\n\u001b[0;32m   1252\u001b[0m       max_workspace_size_bytes\u001b[38;5;241m=\u001b[39mmax_workspace_size_bytes,\n\u001b[0;32m   1253\u001b[0m       precision_mode\u001b[38;5;241m=\u001b[39mprecision_mode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1256\u001b[0m       use_calibration\u001b[38;5;241m=\u001b[39muse_calibration,\n\u001b[0;32m   1257\u001b[0m       allow_build_at_runtime\u001b[38;5;241m=\u001b[39mallow_build_at_runtime)\n\u001b[1;32m-> 1259\u001b[0m \u001b[43m_check_trt_version_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1260\u001b[0m _check_conversion_params(conversion_params, is_v2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conversion_params \u001b[38;5;241m=\u001b[39m conversion_params\n",
      "File \u001b[1;32mc:\\Users\\f1soft\\anaconda3\\envs\\python-39\\lib\\site-packages\\tensorflow\\python\\compiler\\tensorrt\\trt_convert.py:223\u001b[0m, in \u001b[0;36m_check_trt_version_compatibility\u001b[1;34m()\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _pywrap_py_utils\u001b[38;5;241m.\u001b[39mis_tensorrt_enabled():\n\u001b[0;32m    219\u001b[0m   logging\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    220\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow needs to be built with TensorRT support enabled to allow \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF-TRT to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 223\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow has not been built with TensorRT support.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    226\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    227\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows support is provided experimentally. No guarantee is made \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregarding functionality or engineering support. Use at your own risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensorflow has not been built with TensorRT support."
     ]
    }
   ],
   "source": [
    "model.save('saved_model', save_format='tf')\n",
    "\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "conversion_params = trt.TrtConversionParams(\n",
    "    precision_mode=trt.TrtPrecisionMode.FP16,\n",
    "    max_workspace_size_bytes=1 << 25\n",
    ")\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=\"saved_model\",\n",
    "    conversion_params=conversion_params\n",
    ")\n",
    "\n",
    "converter.convert()\n",
    "converter.save(\"trt_saved_model\")\n",
    "\n",
    "trt_model = tf.saved_model.load(\"trt_saved_model\")\n",
    "infer = trt_model.signatures[\"serving_default\"]\n",
    "\n",
    "upscale_and_show_trt('image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Tensorflow needs to be built with TensorRT support enabled to allow TF-TRT to operate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Tensorflow needs to be built with TensorRT support enabled to allow TF-TRT to operate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT 변환 실패 ❌\n",
      "에러 메시지: Tensorflow has not been built with TensorRT support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "try:\n",
    "    converter = trt.TrtGraphConverterV2(\n",
    "        input_saved_model_dir=\"saved_model_srcnn\"\n",
    "    )\n",
    "    converter.convert()\n",
    "    print(\"TensorRT 변환 성공\")\n",
    "except Exception as e:\n",
    "    print(\"TensorRT 변환 실패\")\n",
    "    print(\"에러 메시지:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
